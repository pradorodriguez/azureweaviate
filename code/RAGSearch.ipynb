{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import requests\n",
    "import weaviate\n",
    "from weaviate import EmbeddedOptions\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "from weaviate.classes.query import MetadataQuery, HybridVector, Move\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "aoai_key=os.environ['AZURE_OPENAI_API_KEY']\n",
    "aoai_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "aoai_deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']\n",
    "aoai_embedding=os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "aoai_embedding_3=os.environ['AZURE_OPENAI_EMBEDDINGS_3_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON print beautifier\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Weaviate Embedded DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://localhost:8079/v1/schema\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    client = weaviate.connect_to_local(\n",
    "        port=8079, \n",
    "        grpc_port=50050,    \n",
    "        headers={\n",
    "            \"X-OpenAI-BaseURL\": aoai_endpoint,\n",
    "            \"X-Azure-Api-Key\": aoai_key\n",
    "        }\n",
    "    )\n",
    "    print(\"Connected to existing instance\")\n",
    "else:\n",
    "    client = weaviate.connect_to_embedded(\n",
    "        version=\"1.26.1\",  # e.g. version=\"1.26.5\"\n",
    "        headers={\n",
    "            \"X-OpenAI-BaseURL\": aoai_endpoint,\n",
    "            \"X-Azure-Api-Key\": aoai_key\n",
    "        },\n",
    "    )\n",
    "    print(\"Connected to new instance\")\n",
    "\n",
    "print(client.is_ready())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Weaviate DB metadata\n",
    "json_print(client.get_meta())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Collection (EU Destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.collections.exists(\"eudestinations\"):\n",
    "    client.collections.delete(\"eudestinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.create(\n",
    "    \"eudestinations\",\n",
    "    vectorizer_config=[\n",
    "        Configure.NamedVectors.text2vec_azure_openai(\n",
    "            name=\"title_vector\",            \n",
    "            resource_name=\"aoai-airlift-1\",\n",
    "            deployment_id=aoai_embedding,\n",
    "            base_url=aoai_endpoint\n",
    "        )\n",
    "    ],\n",
    "    generative_config=Configure.Generative.azure_openai(\n",
    "        resource_name=\"aoai-airlift-1\",\n",
    "        deployment_id=aoai_deployment,\n",
    "        base_url=aoai_endpoint\n",
    "        # frequency_penalty=0,\n",
    "        # max_tokens=500,\n",
    "        # presence_penalty=0,\n",
    "        # temperature=0.7,\n",
    "        # top_p=0.7\n",
    "    )\n",
    "    # Additional parameters not shown\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Europe Touristic Destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/eu_destinations_n.json'\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "ds = json.loads(data)\n",
    "json_print(ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(\"eudestinations\")\n",
    "\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for i, d in enumerate(ds):\n",
    "        weaviate_obj = {\n",
    "            \"destination\": d[\"Destination\"],\n",
    "            \"region\": d[\"Region\"],\n",
    "            \"country\": d[\"Country\"],\n",
    "            \"category\": d[\"Category\"],\n",
    "            \"annualtourists\": d[\"Approximate Annual Tourists\"],\n",
    "            \"foods\": d[\"Famous Foods\"],\n",
    "            \"language\": d[\"Language\"],\n",
    "            \"besttimevisit\": d[\"Best Time to Visit\"],\n",
    "            \"costliving\": d[\"Cost of Living\"],\n",
    "            \"cultural\": d[\"Cultural Significance\"],\n",
    "            \"description\": d[\"Description\"]\n",
    "        }\n",
    "\n",
    "        # The model provider integration will automatically vectorize the object\n",
    "        batch.add_object(\n",
    "            properties=weaviate_obj,\n",
    "            # vector=vector  # Optionally provide a pre-obtained vector\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = client.query.aggregate(\"eudestinations\").with_meta_count().do()\n",
    "# json_print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query a specific Collection Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(\"eudestinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.query.fetch_objects(\n",
    "    limit=1\n",
    ")\n",
    "for o in response.objects:\n",
    "    json_print(o.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.query.near_text(\n",
    "    query=\"Picasso\",  # The model provider integration will automatically vectorize the query\n",
    "    limit=5,\n",
    "    include_vector=True,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(obj.properties)\n",
    "    print(obj.metadata.distance)\n",
    "    print(obj.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.query.near_text(\n",
    "    query=\"Picasso\",  # The model provider integration will automatically vectorize the query    \n",
    "    distance=0.20, \n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(obj.properties)\n",
    "    print(obj.metadata.distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse and Dense Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse\n",
    "response = collection.query.bm25(\n",
    "    query=\"Sea\",\n",
    "    return_metadata=MetadataQuery(score=True),\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    json_print(o.properties)\n",
    "    print(o.metadata.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search (Dense and Sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.query.hybrid(\n",
    "    query=\"sea\",\n",
    "    return_metadata=MetadataQuery(score=True, explain_score=True),\n",
    "    limit=3\n",
    "    )\n",
    "\n",
    "for o in response.objects:\n",
    "    json_print(o.properties)\n",
    "    print(o.metadata.score)\n",
    "    print(o.metadata.explain_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alpha of 1 is a pure vector (dense) search.\n",
    "# An alpha of 0 is a pure keyword (sparse) search.\n",
    "response = collection.query.hybrid(\n",
    "    query=\"sea\",\n",
    "    alpha=0.7,\n",
    "    limit=10,\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    json_print(o.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.query.hybrid(\n",
    "    query=\"sea\",\n",
    "    max_vector_distance=0.4,  # Maximum threshold for the vector search component\n",
    "    vector=HybridVector.near_text(\n",
    "        query=\"Scenic view\",\n",
    "        move_away=Move(force=0.5, concepts=[\"Volcano\"]),\n",
    "    ),\n",
    "    alpha=0.75,\n",
    "    limit=10,\n",
    ")\n",
    "for o in response.objects:\n",
    "    json_print(o.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Search with Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Create an itenerary from the {country} ordering by {annualtourists}\"\n",
    "\n",
    "response = collection.generate.near_text(\n",
    "    query=\"sea\",\n",
    "    limit=2,\n",
    "    single_prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.generated)\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.generate.near_text(\n",
    "    query=\"sea\",\n",
    "    limit=2,\n",
    "    target_vector=\"title_vector\",  # Specify the target vector for named vector collections\n",
    "    single_prompt=\"Translate this into Spanish: {cultural}\",\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.generated)\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Create a dish using the Foods\"\n",
    "\n",
    "response = collection.generate.near_text(\n",
    "    query=\"sea\",\n",
    "    limit=5,\n",
    "    grouped_task=task\n",
    ")\n",
    "\n",
    "# print the generated response\n",
    "print(response.generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
